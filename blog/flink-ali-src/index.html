<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="generator" content="Docusaurus v2.0.0-alpha.56">
<title data-react-helmet="true">Flink技术源码解析（一）：Flink概述与源码研读准备 | Flink Lab</title><meta data-react-helmet="true" property="og:title" content="Flink技术源码解析（一）：Flink概述与源码研读准备 | Flink Lab"><meta data-react-helmet="true" name="description" content="一、前言"><meta data-react-helmet="true" property="og:description" content="一、前言"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/styles.f6f3a830.css">
<link rel="preload" href="/styles.027dbade.js" as="script">
<link rel="preload" href="/runtime~main.aaeee84a.js" as="script">
<link rel="preload" href="/main.f5a78f22.js" as="script">
<link rel="preload" href="/common.66399c2c.js" as="script">
<link rel="preload" href="/2.febc0ba0.js" as="script">
<link rel="preload" href="/ccc49370.4332fc13.js" as="script">
<link rel="preload" href="/3576d730.f1567e18.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=window.matchMedia("(prefers-color-scheme: dark)"),n=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==n?t(n):e.matches&&t("dark")}()</script><div id="__docusaurus">
<nav class="navbar navbar--light navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/flink-logo.svg" alt="Flink Logo"><strong class="navbar__title">Flink Lab</strong></a><a class="navbar__item navbar__link" href="/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/flink-lab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_1gtM"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_keGJ moon_1gwN"></span></div><div class="react-toggle-track-x"><span class="toggle_keGJ sun_3CPA"></span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img class="navbar__logo" src="/img/flink-logo.svg" alt="Flink Logo"><strong class="navbar__title">Flink Lab</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/">Docs</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/blog">Blog</a></li><li class="menu__list-item"><a href="https://github.com/flink-lab" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--8 col--offset-2"><article><header><h1 class="margin-bottom--sm blogPostTitle_2RZH">Flink技术源码解析（一）：Flink概述与源码研读准备</h1><div class="margin-vert--md"><time datetime="2018-06-06T00:00:00.000Z" class="blogPostDate_3tRe">June 6, 2018  · 3 min read</time></div><div class="avatar margin-vert--md"><a class="avatar__photo-link avatar__photo" href="https://yq.aliyun.com/users/h34rcygfetceq?spm=a2c4e.11153940.0.0.3055286bED1kYa" target="_blank" rel="noreferrer noopener"><img src="https://ucc.alicdn.com/avatar/img_b31506cca41b90c5502b38e742c21c3e.jpeg" alt="binggozhan"></a><div class="avatar__intro"><h4 class="avatar__name"><a href="https://yq.aliyun.com/users/h34rcygfetceq?spm=a2c4e.11153940.0.0.3055286bED1kYa" target="_blank" rel="noreferrer noopener">binggozhan</a></h4><small class="avatar__subtitle">搜索推荐工程师 @ 阿里口碑</small></div></div></header><section class="markdown"><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="一、前言"></a>一、前言<a aria-hidden="true" tabindex="-1" class="hash-link" href="#一、前言" title="Direct link to heading">#</a></h2><p>Apache Flink作为一款高吞吐量、低延迟的针对流数据和批数据的分布式实时处理引擎，是当前实时处理领域的一颗炙手可热的新星。关于Flink与其它主流实时大数据处理引擎Storm、Spark Streaming的不同与优势，可参考<a href="https://blog.csdn.net/cm_chenmin/article/details/53072498%E3%80%82" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/cm_chenmin/article/details/53072498。</a></p><p>出于技术人对技术本能的好奇与冲动，遂利用业余时间对Flink进行学习研究。Flink源码很庞大，要梳理明白需要投入的时间心力巨大，所以笔者只是针对自己所感兴趣的若干话题展开研究，水平有限如有错误请指正。</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="二、flink概述提要"></a>二、Flink概述提要<a aria-hidden="true" tabindex="-1" class="hash-link" href="#二、flink概述提要" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="21-主要特性与组成"></a>2.1 主要特性与组成<a aria-hidden="true" tabindex="-1" class="hash-link" href="#21-主要特性与组成" title="Direct link to heading">#</a></h3><p>Flink是一个用于流处理和批处理的开源分布式平台，它的核心是流处理引擎（streaming dataflow engine）。</p><p>batch dataset可以视作streaming dataset的一种特例，所以Flink可通过流处理引擎同时处理batch、streaming两种类型的数据。这和spark streaming刚好相反，spark streaming是通过micro batch实现对streaming处理的支持。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="flink的功能特性："></a>Flink的功能特性：<a aria-hidden="true" tabindex="-1" class="hash-link" href="#flink的功能特性：" title="Direct link to heading">#</a></h4><ul><li>可提供准确的结果产出，即使遇到乱序数据、迟到数据；</li><li>有状态可容错（轻量级），可以无感知地从失败中恢复并保持exactly-once的语义（也可以降级为at-least-once进一步降低消息处理延时）；</li><li>可以大规模地运行在成千上万个节点上并保持高吞吐、低延迟，可以standalone模式运行，也可以在YARN和Mesos等资源管理平台上运行；</li><li>灵活地支持多种基于时间、数量、会话的窗口；</li><li>savepoint提供了状态管理机制；</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="flink自下而上的全局组成结构图："></a>Flink自下而上的全局组成结构图：<a aria-hidden="true" tabindex="-1" class="hash-link" href="#flink自下而上的全局组成结构图：" title="Direct link to heading">#</a></h4><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/9FLlwL.png" alt="img"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="22-编程模型"></a>2.2 编程模型<a aria-hidden="true" tabindex="-1" class="hash-link" href="#22-编程模型" title="Direct link to heading">#</a></h3><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="221-flink提供的api"></a>2.2.1 Flink提供的API<a aria-hidden="true" tabindex="-1" class="hash-link" href="#221-flink提供的api" title="Direct link to heading">#</a></h4><p>Flink提供了不同层次的API用于streaming/batch应用的开发，如下图所示：</p><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/HyBa73.png" alt="img"></p><p>最底层的抽象仅提供状态流（stateful streaming），它通过处理函数嵌入到DataStream API中。</p><p>实践中用Core API比较多，这些流式的API提供了通用的构建入口用于数据处理，像各种用户自定义的transformation、join、aggregation、window、state等。</p><p>Table API是以表为中心的声明式DSL（领域特定语言），当这些Table表示的是stream时，Table是动态变化的。Table API遵循扩展的关系模型，提供了包括select、project、join、group-by、aggregate等操作。</p><p>Flink提供的最高层级的API是SQL，它在语义和表达能力上与Table API是类似的。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="222-flink程序与streaming-dataflow"></a>2.2.2 Flink程序与Streaming Dataflow<a aria-hidden="true" tabindex="-1" class="hash-link" href="#222-flink程序与streaming-dataflow" title="Direct link to heading">#</a></h4><p>Flink程序的基本元素包括：</p><p>Stream：由连续不断的data record组成的数据流。
transformation：是一种转换操作，作用在一个或多个stream上，输出一个或多个stream。
每个Flink程序可以映射为一个streaming dataflow，这个dataflow由stream和transformation operator组成。每个dataflow是一个DAG，从一个或多个source开始，结束于一个或多个sink。</p><p>Flink程序Streaming dataflow的结构如下图所示：</p><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/mZqapX.png" alt="img"></p><p>一个标准Flink程序的组成：</p><ul><li>获取一个执行环境（StreamExecutionEnvironment用于流处理，ExecutionEnvironment用于批处理），执行环境可以决定将下面的计算放在本地jvm运行还是提交到Flink集群中运行；</li><li>加载初始数据；</li><li>在数据上指定需要执行的transformation；</li><li>指定将计算结果写到哪里；</li><li>触发程序执行；</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="223-并行的dataflow"></a>2.2.3 并行的dataflow<a aria-hidden="true" tabindex="-1" class="hash-link" href="#223-并行的dataflow" title="Direct link to heading">#</a></h4><p>Flink程序在实际运行中是并行的、分布式的：</p><p>一个stream会被拆分为一个或多个stream partitions。</p><p>一个transformation operator可以拆分为一个或多个operator subtask（subtask的数量称为这个operator的并行度）。每个operator subtask和其它的operator subtask相互独立，并运行在不同的线程中（甚至在不同的机器上）Flink程序中的source、sink也都属于transformation operator。</p><p>一个transformation operator中的operator subtask个数就是这个operator的并行度；一个stream的并行度为对应的producing operator（从数据源读数据的operator）的个数。一个程序中的不同operator可能会有不同的并行度。</p><p>一个dataflow的运行结构如下图所示：</p><p> <img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/9JtCM6.png" alt="img"></p><p>流中的数据在不同operator之间的传递方式有两种：</p><ul><li><p>one-to-one：像上图的Source[1] -&gt; map[1]。</p></li><li><p>redistributing：像上图的map[1] -&gt; keyBy()/window()/apply() [1]和[2]。</p></li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="224-window"></a>2.2.4 Window<a aria-hidden="true" tabindex="-1" class="hash-link" href="#224-window" title="Direct link to heading">#</a></h4><p>在streams上对event进行聚合（如count、sum）与批处理不同，需要通过window限定聚合的event范围，如统计最近5分钟的event数量。stream上的window可以是时间驱动（如每30秒），也可以是数据驱动（如每100个元素）。</p><p>window类型的典型划分：</p><ul><li>tumbling windows：不同window之间的元素不重叠。</li><li>sliding window：不同window之间的元素可重叠。</li><li>session window：即通过会话来区分window。</li></ul><p>一个stream上可以同时有多个window：</p><p> <img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/6QMI6n.png" alt="img"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="225-有状态的operation"></a>2.2.5 有状态的Operation<a aria-hidden="true" tabindex="-1" class="hash-link" href="#225-有状态的operation" title="Direct link to heading">#</a></h4><p>dataflow中很多operator在一个时间点通常只关注一个event，是无状态的；而有些operator会需要记忆跨多个event的信息，这些operator就是有状态的。</p><p>有状态的operator的状态以key/value的形式存储（在内存、HDFS或RocksDB中），并与stream一起被分割分布式存储。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="226-checkpoint与容错"></a>2.2.6 Checkpoint与容错<a aria-hidden="true" tabindex="-1" class="hash-link" href="#226-checkpoint与容错" title="Direct link to heading">#</a></h4><p>Flink通过流重放（stream replay）、检查点（checkpointing）来实现容错。</p><p>checkpoint存储的信息包括某个特定event在stream中的偏移量、dataflow中相关operator处理到这个event时的状态。</p><p>一个stream dataflow可以从一个任意指定的checkpoint恢复（加载checkpoint中各operator的状态，然后从stream中指定event位置开始重放），同时保证exactly-once语义。</p><p>对flink的checkpoint时间间隔，如果设置的较长，则容错开销小，但是从checkpoint恢复时间长（因为需要重放很多的event）；如果设置的较短，则恢复很快，但是容错开销大（存储了很多checkpoints）。</p><p>需要说明的是，Flink将批处理看做流处理的一种特殊情形（即stream是有界的情形）。Flink对批处理并不用checkpoint，因为考虑到batch data是有限的，当处理数据失败了把所有数据重放一遍即可。因而批处理中处理event会更快（因为避免了checkpoint）。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="227-watermark"></a>2.2.7 WaterMark<a aria-hidden="true" tabindex="-1" class="hash-link" href="#227-watermark" title="Direct link to heading">#</a></h4><p>WaterMark（包含一个时间戳）可以像正常的element一样插入到stream中，用于告诉operator不会有比它自己更晚的element到来。WaterMark在source中发射，并通过operator在stream中向下传播。</p><p>watermark只是启发式的，如果有比watermark的event time早的element在watermark之后到，operator仍然需要支持处理（抛弃或更新结果）。当source发了一个最终的watermark（时间戳为Long.MAX_VALUE），收到它的operator就知道不会有更多的输入了。</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="23-分布式runtime"></a>2.3 分布式runtime<a aria-hidden="true" tabindex="-1" class="hash-link" href="#23-分布式runtime" title="Direct link to heading">#</a></h3><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="231-任务链与oprator链"></a>2.3.1 任务链与Oprator链<a aria-hidden="true" tabindex="-1" class="hash-link" href="#231-任务链与oprator链" title="Direct link to heading">#</a></h4><p>为了能够分布式执行，Flink将operator subtask链式拼接为一个task，每个task由一个线程来执行。这是一个很有用的优化，它可以降低线程之间的切换开销，增加Flink的吞吐量，并降低处理延时。</p><p>下图展示的是一个dataflow，其中涉及到source、map()、keyBy()/window()/apply()、sink等operator。</p><p>source和map分别都被拆分为两个operator subtask并各分配一个线程，其中考虑到event在source、map中的传输方式是one-to-one所以将source和map链接在同一个线程里；
keyBy()/window()/apply()也被拆分为两个operator subtask并各占一个线程；</p><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/OfYBo3.png" alt="img"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="232-jobmanagertaskmanagerclient"></a>2.3.2 JobManager/TaskManager/Client<a aria-hidden="true" tabindex="-1" class="hash-link" href="#232-jobmanagertaskmanagerclient" title="Direct link to heading">#</a></h4><p>Flink运行时包含两种类型的进程：</p><ol><li><p>JobManager（master）：协调job的分布式执行，具体包括调度task、协调checkpoint、协调从失败中恢复等。在实际部署中，至少有一个JobManager，高可用模式下会有多个JobManager（一个作为leader其它作为standby）。</p></li><li><p>TaskManager（worker）：负责dataflow中task的具体执行（更具体地说是subtask）。TaskManager需要连接到JobManager，告诉它自己是可用的，并等待被分配任务。在实际部署中，也至少有一个TaskManager。</p></li></ol><p>在单机伪分布模式下，只有JobManager进程，而TaskManager会作为JobManager进程中的一个线程。</p><p>JobManager和TaskManager可以直接在机器上启动，也可以通过资源管理框架（如YARN、Mesos）来管理启动。</p><p>Client不是Flink运行时的组成部分，被用于向JobManager发送Job（此后可以断开连接或者等待JobManager的任务执行进度报告）。</p><p>JobManager、TaskManager和Client之间的交互如下图所示：</p><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/yFGn0a.png" alt="img"> </p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="233-task槽（slot）与资源"></a>2.3.3 Task槽（slot）与资源<a aria-hidden="true" tabindex="-1" class="hash-link" href="#233-task槽（slot）与资源" title="Direct link to heading">#</a></h4><p>每个TaskManager是一个JVM进程，会在不同的线程中执行一个或多个operator subtask。为了控制单个TaskManager所能接收的任务数量，每个TaskManager会包含一组Task槽（至少会有一个）。</p><p>一个Task槽表示TaskManager JVM进程中一组固定的资源，可以被一个或多个线程（或operator subtask）共享。</p><p>例如，对一个包含3个Task槽的TaskManager，它会把进程中1/3的资源（如内存）分配给各个槽。不同Task槽中的subtask互相独立不会互相争夺资源，但是会共享JVM中的TCP连接、心跳消息。Task槽目前只是用于隔离Task使用的内存。</p><p>TaskManager JVM中operator subtask、thread、task slot之间的关系：</p><p>一个TaskManager JVM进程会有一个或多个Task Slot（个数一般与cpu core的个数相等），每个Task Slot能分配到这个JVM中的一部分资源（内存）；
一个Task Slot（中的资源）可以被一个或多个线程共享。一个线程中运行一个operator subtask或链接起来的多个operator subtask。</p><p><img src="https://img-upic.oss-accelerate.aliyuncs.com/uPic/2020%10/06/Ni2Wd7.png" alt="img"></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="234-状态存储"></a>2.3.4 状态存储<a aria-hidden="true" tabindex="-1" class="hash-link" href="#234-状态存储" title="Direct link to heading">#</a></h4><p>上文讲到，streaming dataflow中的一些operator（如windows）是有状态的。这些状态（被索引的键值对）作为checkpoint的一部分，可以存储在内存/HDFS/RocksDB中（通过配置控制）。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="235-保存点（savepoint）"></a>2.3.5 保存点（savepoint）<a aria-hidden="true" tabindex="-1" class="hash-link" href="#235-保存点（savepoint）" title="Direct link to heading">#</a></h4><p>使用DataStream API编写的Flink程序可以从任意指定的savepoint开始执行。Savepoint允许你“冻结”stream的处理、更新你的flink程序甚至你的flink集群（如升级版本），然后可以从savepoints恢复执行。</p><p>savepoint是手工触发的checkpoints，也依赖checkpointing机制，可以对当前的状态生成快照并保存。</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="24-api库"></a>2.4 API&amp;库<a aria-hidden="true" tabindex="-1" class="hash-link" href="#24-api库" title="Direct link to heading">#</a></h3><p>Flink程序从source中读数据（如file/内存/kafka topic），在数据集上实现转换（如filtering/mapping/updating state/joining/grouping/defining windows/aggregating等），并将完成一系列转换处理后的数据写到sink中（如file/终端）。我们可以用DataStream API处理streaming数据，可以用DataSet API处理batch数据。</p><p>Flink API的基本概念参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/api_concepts.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/api_concepts.html。</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="241-flink提供的api"></a>2.4.1 Flink提供的API<a aria-hidden="true" tabindex="-1" class="hash-link" href="#241-flink提供的api" title="Direct link to heading">#</a></h4><ol><li>DataStream API</li></ol><p>在data stream上实现转换，如filter、update state、define windows、aggregate。DataStream中的transformation可以将一个或多个DataStream转换为一个DataStream。API参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/datastream_api.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/datastream_api.html。</a></p><p>常用的转换算子包括：</p><ul><li>map：输入一个element产生另一个element；</li><li>flatMap：输入一个element产生0个或多个element；</li><li>filter：对一个element，仅当布尔函数返回true时保留这个element；</li><li>keyBy：按照某个指定的key的值，将一个stream划分为多个不相交的partition，一个partition中所有element的这个key的值相同；</li><li>reduce：将当前的element与最近一次生成的reduced值进行合并，然后消除这个element（reduce作用在经过keyBy的数据流上）；</li><li>fold：类似于reduce，但它是对流中的element进行折叠；</li><li>聚合算子，包括min、minBy、max、maxBy；</li><li>window：一个流被keyBy划分为若干个partition后，对各partition可以执行window，比如收集最近5分钟的数据；</li><li>window apply/reduce/fold/聚合：对一个window中的数据进行某种处理；</li><li>union：将多个流合并为一个流，这个流包含这些流的所有element；</li></ul><p>对于stream的partition，Flink提供了自定义功能对partition过程进行定制。</p><p>我们可以把不同的算子链接到一起，使得它们在一个相同的线程中运行以获得更好的性能表现。默认情况下，Flink会尽可能地将能链接到一起的算子链接到一起。但我们可以使用类似于startNewChain()、disableChaining()进行干预。</p><p>   data source：数据源可以是基于文件的、基于socket的、基于集合的，对于这些类型的数据源Flink都提供了接口可以直接从指定文件或socket或集合读入数据流。Flink也支持自定义source function，如从kafka中读取数据流。Flink支持为读取的element打上时间戳。</p><p>   data sink：可以将经过各种算子处理后的数据流写到文件、csv、socket中，也可以写到自定义的sink（如kafka）。</p><ol start="2"><li><p>DataSet API</p><p>DataSet API在data set上实现转换，如filter、map、join、group。</p><p>DataSet API和DataStream API类似（大部分算子），少数特有的如下：</p><ul><li>groupBy：类似于DataStream API中的keyBy；</li><li>dinstinct：返回数据集中的所有不同元素；</li><li>其它；</li></ul></li></ol><p>API参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/index.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/batch/index.html。</a></p><ol start="3"><li>Table API &amp; SQL</li></ol><p>Table API是一种类SQL表达式语言，可以用于关系流（relational stream）和batch，可以嵌入到DataStream API和DataSet API中。</p><p>Flink的SQL支持是基于Apache Calcite实现的，其中Apache Calcite实现了SQL标准。</p><p>Flink的Table API和SQL尚未完全实现，并非所有的功能都能支持，还在开发中。</p><p>API参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/index.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/table/index.html。</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="242-flink提供的库"></a>2.4.2 Flink提供的库<a aria-hidden="true" tabindex="-1" class="hash-link" href="#242-flink提供的库" title="Direct link to heading">#</a></h4><p>基于Flink的更高level的库包括： </p><p>CEP：事件处理库。它可以允许你在一个无尽的流中检测特定的event，从而处理流中你特别关注的event。
Gelly：是一个图计算用的库，它提供了一组方法和工具用于简化图分析。
Machine Learning：Flink社区在推送实现的一个机器学习库，实现常用的机器学习算法，如SVM、多元线性回归、K近邻等。 </p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="25-flink监控"></a>2.5 Flink监控<a aria-hidden="true" tabindex="-1" class="hash-link" href="#25-flink监控" title="Direct link to heading">#</a></h3><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="251-metric监控"></a>2.5.1 Metric监控<a aria-hidden="true" tabindex="-1" class="hash-link" href="#251-metric监控" title="Direct link to heading">#</a></h4><p>Flink包含了一个metric系统，可采集用户范围/系统范围的监控指标并输出给外部监控系统，如Ganglia/Graphite/StatsD等。采集的监控指标包括CPU、内存、线程、垃圾收集、类加载器、网络、集群、高可用、checkpointing、IO、source连接器等。</p><p>开发者可以在用户函数中访问metric系统，自定义并统计metric。</p><p>详情可参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/metrics.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/metrics.html。</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="252-checkpoint监控"></a>2.5.2 Checkpoint监控<a aria-hidden="true" tabindex="-1" class="hash-link" href="#252-checkpoint监控" title="Direct link to heading">#</a></h4><p>Flink提供了dashboard用于监控Job的checkpoint。即使Job完成运行，对应的checkpoint统计数据仍然是可以查询的。详情可以参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/checkpoint_monitoring.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/checkpoint_monitoring.html。</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="253-back-pressure监控"></a>2.5.3 Back Pressure监控<a aria-hidden="true" tabindex="-1" class="hash-link" href="#253-back-pressure监控" title="Direct link to heading">#</a></h4><p>如果你看到一个task的背压（back pressure）告警，这表示这个task产生数据的速度超过了下游operator的消费速度。数据在job flow中是按照从source到sink的方向流动的，而背压是沿着相反的方向传播。</p><p>详情可以参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/back_pressure.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/back_pressure.html。</a></p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="254-监控rest-api"></a>2.5.4 监控REST API<a aria-hidden="true" tabindex="-1" class="hash-link" href="#254-监控rest-api" title="Direct link to heading">#</a></h4><p>Flink基于Netty提供了一组监控API用于查询正在运行/最近完成的Job的状态和统计数据，这些API用于输出监控数据给Flink自身的Dashboard，但是也可以用于开发定制化的监控工具。</p><p>详情可以参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/rest_api.html%E3%80%82">https://ci.apache.org/projects/flink/flink-docs-release-1.4/monitoring/rest_api.html。</a></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="三、job开发"></a>三、Job开发<a aria-hidden="true" tabindex="-1" class="hash-link" href="#三、job开发" title="Direct link to heading">#</a></h2><p>想了下这里还是不准备写成step-by-step类的manual了，就只是简略地提供一些基本步骤和参考代码及文档</p><ol><li>根据flink java template创建空的job project</li></ol><p>cd到你的指定目录，执行：</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">mvn archetype:generate -DarchetypeGroupId=org.apache.flink -DarchetypeArtifactId=flink-quickstart-java -DarchetypeVersion=1.4.2</span></div></div></div></div></div><p>执行过程中会提示让你输入groupId、artifactId、version等，最终生成一个空的job project，其中包含两个Job示例（BatchJob/StreamingJob，可自行删除）。上述版本号可以选用任意flink已发布版本，最新版本号是1.5.0。</p><p>通过模板生成project，可以省去繁琐的maven pom配置工作。</p><p>参考：</p><p>[1] <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/java_api_quickstart.html">https://ci.apache.org/projects/flink/flink-docs-release-1.4/quickstart/java_api_quickstart.html</a></p><p>[2] <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/start/dependencies.html">https://ci.apache.org/projects/flink/flink-docs-release-1.4/start/dependencies.html</a></p><ol start="2"><li>Job开发与打包</li></ol><p>使用一个趁手的IDE（如IDEA），将上述项目导入到IDE中即可开始编码。Flink在其源码中提供了一个maven分包flink-examples，内含批处理job和流处理job示例，可参考编写。</p><p>Flink Job开发的一些tips：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/best_practices.html">https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/best_practices.html</a></p><p>完成开发后执行mvn clean package即可编译打包，你的job以及依赖的flink connector、library（如CEP/SQL/ML等）会被集成到jar包中，而flink core相关的jar包不会被放进去。</p><ol start="3"><li>提交运行</li></ol><p>将Job jar包通过flink提供的CLI工具提交到Flink集群运行。执行命令示例：</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">./bin/flink run examples/streaming/SocketWindowWordCount.jar --port 9000</span></div></div></div></div></div><p>其中，SocketWindowWordCount.jar是你开发打包生成的jar包，--port 9000是这个job自定义的参数。</p><p>CLI工具参考：<a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/cli.html">https://ci.apache.org/projects/flink/flink-docs-master/ops/cli.html</a></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="四、flink源码研读准备"></a>四、Flink源码研读准备<a aria-hidden="true" tabindex="-1" class="hash-link" href="#四、flink源码研读准备" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="41-脚本分析"></a>4.1 脚本分析<a aria-hidden="true" tabindex="-1" class="hash-link" href="#41-脚本分析" title="Direct link to heading">#</a></h3><p>Flink提供了系列shell脚本用于flink集群管理、job提交等，通过分析这些脚本找到自己所关心的核心链路入口是比较合适的。</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="411-启动脚本"></a>4.1.1 启动脚本<a aria-hidden="true" tabindex="-1" class="hash-link" href="#411-启动脚本" title="Direct link to heading">#</a></h4><p>Flink提供了两个启动脚本：bin/start-local.sh用于启动单机模式的Flink；bin/start-cluster.sh用于启动集群模式的Flink。</p><ol><li>start-local.sh</li></ol><p>解析提取<code>flink-yaml.xml</code>中的配置项，各配置项的含义可参考<a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/config.html">config.html</a>。以daemon模式启动jobmanager进程（并分出一个线程启动taskmanager）。</p><ol start="2"><li>start-cluster.sh</li></ol><p>解析提取<code>flink-yaml.xml</code>中的配置项。通过ssh远程启动各master机器上的jobmaster进程（需要在<code>conf/masters</code>中配置master机器的ip地址，默认是localhost:8081）。启动taskmanager进程（需要在<code>conf/slaves</code>配置slave机器的ip地址，通常是localhost）。
由<code>flink-daemon.sh</code>可知，Flink中各主要进程的入口对应关系如下：</p><ul><li>jobmanager -&gt; org.apache.flink.runtime.jobmanager.JobManager</li><li>taskmanager -&gt; org.apache.flink.runtime.taskmanager.TaskManager</li><li>内置zookeeper -&gt; org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer</li><li>historyserver -&gt; org.apache.flink.runtime.webmonitor.history.HistoryServer</li></ul><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="412-cli脚本"></a>4.1.2 CLI脚本<a aria-hidden="true" tabindex="-1" class="hash-link" href="#412-cli脚本" title="Direct link to heading">#</a></h4><p>Flink提供的CLI脚本是<code>bin/flink</code>，可以通过该脚本提交Job、创建Savepoint等。</p><p>脚本的主要流程：</p><ul><li>解析提取<code>flink-yaml.xml</code>中的配置项。</li><li>通过Client入口<code>org.apache.flink.client.CliFrontend</code>连接到JobManager并发送消息。</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_ZqCz" id="42-源码debug方法"></a>4.2 源码debug方法<a aria-hidden="true" tabindex="-1" class="hash-link" href="#42-源码debug方法" title="Direct link to heading">#</a></h3><p>Flink是开源的，代码托管在Github上，可以选择一个合适的版本将Flink源码clone下来。也可以直接从Flink官网上下载下来，链接<a href="http://flink.apache.org/downloads.html#source%E3%80%82Flink%E6%BA%90%E7%A0%81%E7%9A%84%E7%BB%84%E6%88%90%E7%BB%93%E6%9E%84%E6%B8%85%E6%99%B0%E6%98%8E%E4%BA%86%EF%BC%8C%E6%AF%8F%E4%B8%AA%E5%88%86%E5%8C%85%E7%9A%84%E5%8A%9F%E8%83%BD%E8%A7%81%E5%90%8D%E7%9F%A5%E6%84%8F%E3%80%82">http://flink.apache.org/downloads.html#source。Flink源码的组成结构清晰明了，每个分包的功能见名知意。</a></p><p>编译源码：</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">mvn clean install -DskipTests -Dmaven.javadoc.skip=true -Dcheckstyle.skip=true</span></div></div></div></div></div><p>参考：<a href="https://ci.apache.org/projects/flink/flink-docs-master/start/building.html">https://ci.apache.org/projects/flink/flink-docs-master/start/building.html</a></p><p>将源码导入到IDE中（如IDEA），本地debug基本方法如下：</p><ol><li><p>在jvm启动参数中添加远程调试参数</p><ol><li><p>如果是调试Client，可以将上述参数加到bin/flink脚本的最后一行中，形如：</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">JVM_REMOTE_DEBUG_ARGS=&#x27;-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005&#x27;</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">exec $JAVA_RUN $JVM_ARGS $JVM_REMOTE_DEBUG_ARGS &quot;${log_setting[@]}&quot; -classpath &quot;`manglePathList &quot;$CC_CLASSPATH:$INTERNAL_HADOOP_CLASSPATHS&quot;`&quot; org.apache.flink.client.CliFrontend &quot;$@&quot;</span></div></div></div></div></div></li><li><p>如果是调试JobManager或TaskManager，可以在<code>conf/flink-conf.yaml</code>中添加：</p><div class="mdxCodeBlock_iHAB"><div class="codeBlockContent_32p_"><button type="button" aria-label="Copy code to clipboard" class="copyButton_1BYj">Copy</button><div tabindex="0" class="prism-code language-undefined codeBlock_19pQ"><div class="codeBlockLines_2n9r" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">env.java.opts: -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5006</span></div></div></div></div></div></li></ol></li><li><p>启动flink client或jobmanager或taskmanager，此时程序会suspend等待debuger连接（通过suspend=y来配置）。</p></li><li><p>配置IDEA中的remote：host配置为localhost，配置port（参考1中的配置的address端口）。</p></li><li><p>在Flink源码中设置断点，连接远程host，然后就可以开始debug跟踪了。</p></li></ol></section><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/flink">flink</a><a class="margin-horiz--sm" href="/blog/tags/debug">debug</a></div></footer></article><div><a href="https://github.com/flink-lab/home-page/edit/master/blog/blog/2018-06-06-flink-ali-src.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 40 40" style="margin-right:0.3em;vertical-align:sub"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="margin-vert--xl"><nav class="pagination-nav"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/flink-tutorial"><div class="pagination-nav__sublabel">Previous Post</div><div class="pagination-nav__label">« Advanced Apache Flink Tutorial 1 - Analysis of Runtime Core Mechanism</div></a></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/">Stream Switch</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://flink-lab.slack.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack</a></li><li class="footer__item"><a href="https://github.com/flink-lab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Links</h4><ul class="footer__items"><li class="footer__item"><a href="https://flink.apache.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flink</a></li><li class="footer__item"><a href="https://community.alibabacloud.com/users/5782759541479310?spm=a2c65.11461447.0.0.41204a012XdZla" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apache Flink Community China</a></li><li class="footer__item"><a href="https://v2.docusaurus.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docusaurus</a></li></ul></div></div><div class="text--center"><div>Copyright © 2020 Flink Lab. Built with v2.docusaurus.io</div></div></div></footer></div>
<script src="/styles.027dbade.js"></script>
<script src="/runtime~main.aaeee84a.js"></script>
<script src="/main.f5a78f22.js"></script>
<script src="/common.66399c2c.js"></script>
<script src="/2.febc0ba0.js"></script>
<script src="/ccc49370.4332fc13.js"></script>
<script src="/3576d730.f1567e18.js"></script>
</body>
</html>